---
id: max-flow
title: 'Maximum Flow'
author: Benjamin Qi
prerequisites:
  - unweighted-shortest-paths
description: Introduces maximum flow as well as flow with lower bounds.
frequency: 1
---

<Problems problems="maxSam" />

## Solution

The code below uses the [Edmonds-Karp](https://en.wikipedia.org/wiki/Edmonds%E2%80%93Karp_algorithm) algorithm.

We can use a greedy approach to solve this.
The download speed (the flow) can be improved as long as we can find a non-negative capacity path from the source (the server) and the sink (Kotivalo's computer).
After that, we subtract the minimum capacity on the found path from the edge capacities.

<LanguageSection>
<CPPSection>

```cpp
#include <bits/stdc++.h>
using namespace std;

long long max_flow(vector<vector<long long>> g, int n, int source, int sink) {
	long long flow = 0;
	vector<int> parent(n, -1);

	// Find a way from the source to sink on a path with non-negative capacities
	auto reachable = [&]() -> bool {
		queue<int> q;
		q.push(source);
		while (!q.empty()) {
			int node = q.front();
			q.pop();
			for (int son = 0; son < n; son++) {
				long long w = g[node][son];
				if (w <= 0 || parent[son] != -1) continue;
				parent[son] = node;
				q.push(son);
			}
		}
		return parent[sink] != -1;
	};

	// While there is a way from source to sink with non-negative capacities
	while (reachable()) {
		int node = sink;

		// The minimum capacity on the path from source to sink
		long long curr_flow = LLONG_MAX;
		while (node != source) {
			curr_flow = min(curr_flow, g[parent[node]][node]);
			node = parent[node];
		}
		node = sink;
		while (node != source) {
			// Subtract the capacity from capacity edges
			g[parent[node]][node] -= curr_flow;
			// Add the current flow to flow backedges
			g[node][parent[node]] += curr_flow;
			node = parent[node];
		}
		flow += curr_flow;
		fill(parent.begin(), parent.end(), -1);
	}

	return flow;
}

int main() {
	int n, m;
	cin >> n >> m;

	vector<vector<long long>> capacity(n, vector<long long>(n, 0));
	for (int i = 0; i < m; i++) {
		int x, y, c;
		cin >> x >> y >> c;
		capacity[--x][--y] += c;
	}

	cout << max_flow(capacity, n, 0, n - 1) << endl;
}
```

</CPPSection>
</LanguageSection>

## Resources

<Resources>
	<Resource
		source="CPC"
		title="10 - Network Flow"
		url="10_graphs_3_network_flow"
	/>
	<Resource source="CPH" title="20 - Flows & Cuts"/>
	<Resource
		source="CP2"
		title="4.6, 4.7.4 - Max Flow, Bipartite Graphs"
	 />
</Resources>

## Flows

<Problems problems="flow" />

## Bipartite Matching

<Problems problems="match" />

It is more than recommended to solve the first problem - Download Speed - in the section before jumping to this one.

### Solution 1

A bipartite graph doesn't seem like to have anything in common with a flow network, but we can shift our point of view just by
adding the source connected to the nodes in set $U$ and the sink connected to the nodes in set $V$. And that's all.
Now we have a flow network where every capacity is equal to 1.

The reason we transformed our bipartite graph into a network flow is that the maximum network flow is equal
to the maximum matching. We can now apply Edmonds-Karp or Ford-Fulkerson algorithm.

**Time Complexity: $\mathcal{O}(VE^2)$**

### Solution 2

We can achieve a better complexity than $\mathcal{O}(VE^2)$, but first let's define some properties of matching algorithms.

Let's say the set $M$ contains all the edges that the maximum matching consists of.

We define an **alternating path** as a path whose edges are in the matching, $M$, and not in the matching, in an alternating fashion. An alternating path stars with an unmatched node and ends once it cannot append another edge while maintaining an alternating sequence.

An **augmenting path** is built upon the alternating path and unmatched nodes at both ends - the nodes are not included in $M$.

Tha maximum matching $M$ can be further improved if and only if an augmenting path is found in $M$, otherwise $M$ is the maximum matching. It may seem difficult to understand, but the main idea is: ``The maximum matching can be further improved as long as the alternating sequence can be extended ``. For a better understanding, you can imagine the shoelaces as an alternating path in a bipartite graph - or the sneakers.

The algorithm described above is called the [Hopcroft-Karp algorithm](https://en.wikipedia.org/wiki/Hopcroft%E2%80%93Karp_algorithm).

**Time Complexity: $\mathcal{O}(E\sqrt{V})$**

Here is an animation of how the code belowe works:

<video width="960" height="720" controls>
	<source src="/animations/Hopcroft-Karp.mp4" type="video/mp4"/>
</video>

<LanguageSection>
<CPPSection>
```cpp
#include <bits/stdc++.h>

using namespace std;

const int INF = 1e9;

int n, m, k;
// dist[node] = the position of node in the alternating path
vector<int> Pair, dist;
vector<vector<int>> g;

bool bfs() {
	queue<int> q;
	// The alternating path starts with unmatched nodes
	for (int node = 1; node <= n; node++) {
		if (!Pair[node]) {
			q.push(node);
			dist[node] = 0;
		} else {
			dist[node] = INF;
		}
	}

	dist[0] = INF;

	while (!q.empty()) {
		int node = q.front();
		q.pop();
		if (dist[node] >= dist[0]) continue;
		for (auto son : g[node]) {
			// If the pair of son is matched
			if (dist[Pair[son]] == INF) {
				dist[Pair[son]] = dist[node] + 1;
				q.push(Pair[son]);
			}
		}
	}
	// Returns true if an alternating path has been found
	return dist[0] != INF;
}

// Returns true if an augmenting path has been found starting from vertex node
bool dfs(int node) {
	if (node == 0) return true;
	for (auto son : g[node]) {
		if (dist[Pair[son]] == dist[node] + 1 && dfs(Pair[son])) {
			Pair[node] = son;
			Pair[son] = node;
			return true;
		}
	}
	dist[node] = INF;
	return false;
}

int Hopcroft_Karp() {
	int match = 0;
	// While there is an alternating path
	while (bfs()) {
		for (int node = 1; node <= n; node++) {
			// If node is unmatched but we can match it using an augmenting path
			if (!Pair[node] && dfs(node)) { match++; }
		}
	}
	return match;
}

// Hopcroft-Karp algorithm
int main() {
	scanf("%d %d %d", &n, &m, &k);

	dist.resize(n + m + 1);
	Pair.resize(n + m + 1);
	g.resize(n + m + 1);

	for (int i = 1; i <= k; i++) {
		int x, y;
		scanf("%d %d", &x, &y);

		y += n;

		g[x].push_back(y);
		g[y].push_back(x);
	}

	printf("%d\n", Hopcroft_Karp());

	for (int node = 1; node <= n; node++) {
		if (Pair[node]) { printf("%d %d\n", node, Pair[node] - n); }
	}
	return 0;
}
```
</CPPSection>
</LanguageSection>

## Dinic's Algorithm

<YouTube id="M6cm8UeeziI" />

<Problems problems="dinic" />

Hopcroft-Karp Bipartite Matching?

<Optional title="Faster Flow">

There exist faster flow algorithms such as **Push-Relabel**. Also see the
following blog post:

- [Chilli: Dinic's with Scaling](https://codeforces.com/blog/entry/66006)

However, the standard implementation of Dinic's is (almost) always fast enough
on reasonable problems.

</Optional>

### Implementation

<Resources>
	<Resource
		source="Benq"
		url="https://github.com/bqi343/USACO/blob/master/Implementations/content/graphs%20(12)/Flows%20(12.3)/Dinic.h"
		title="Dinic"
	/>
</Resources>

## Breaking Flows

When the constraints are too high ...

<Resources>
	<Resource
		source="CF"
		url="https://codeforces.com/blog/entry/80627"
		title="maroonrk - TL Issue on CF 659 Div 1 F"
		starred
	/>
	<Resource
		source="CF"
		url="https://codeforces.com/blog/entry/52714?#comment-668566"
		title="Actual Complexity of Max Flow?"
		starred
	/>
</Resources>
